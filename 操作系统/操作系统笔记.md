## 一、操作系统引论

1、操作系统的目标：有效性、方便性、可扩充性、开放性。

2、操作系统的作用：为用户和计算机系统之间提供接口、管理计算机系统资源、对计算机资源

3、操作系统的发展：人工操作、脱机输入输出、单道批处理系统、**多道批处理系统**（真正的操作系统）、分时系统、实时系统。

- 单道批处理系统特点
  - 自动性：作业自动逐个运行。
  - 顺序性：顺序进入内存，顺序完成操作。
  - 单道性：内存只有一道程序运行。

- 多道批处理系统

  用户提交的作业在外存排队，构成后备队列；之后，由作业调度程序从后备队列中选择若干作业调入内存，共享 CPU 和系统资源。

  - 多道批处理系统优缺点：
    - 优点：资源利用率高、系统吞吐量大（单位时间内完成的总工作量）
    - 缺点：平均周转时间长（从作业进入系统，到完成并退出系统为止的时间）、无交互能力

- 分时系统

  一台主机连接了若干个终端，每个终端有一个用户在使用，向系统提出命令请求，系统接受每个用户的命令，采用**时间片轮转**方式处理服务请求，通过交互方式在终端上向用户显示结果。

  - 分时系统的特点
    - 多路性：一个主机连接多台终端，按分时原则为多个用户服务。
    - 独立性：一个用户一个终端，操作独立
    - 及时性：时可以在很短时间内获得响应。
    - **交互性**：人机对话。

- **实时系统与批处理系统和分时系统的区别**

  - 专用系统：许多实时系统是专用系统，而批处理与分时系统通常是通用系统
  - 实时控制：实时系统用于控制实时过程，要求对外部事件的迅速响应，具有较强的中断处理机构
  - 高可靠性：实时系统用于控制重要过程，要求高度可靠
  - 事件驱动和队列驱动：实时系统的工作方式：接受外部消息，分析消息，调用相应处理程序进行处理。

4、操作系统的基本特性：并发性、共享性（互斥共享、同时访问）、虚拟性（时分复用、空分复用）、异步性。

>并发性指的是多个事件在**同一时间间隔**内发生。并行性是多个事件在同一时刻发生。

5、操作系统的主要功能：处理机管理、存储器管理、设备管理功能、文件管理功能、操作系统与用户之间的接口。

- 处理机管理
  1. 进程控制：创建进程、撤销结束进程、控制进程状态转换。
  2. 进程同步，为多个进程运行进行协调，协调方式有：
     - 进程互斥方式：对临界资源访问时，采用互斥。
     - 进程同步方式：完成共同任务的进程（线程）间，由同步机构对执行次序协调。
  3. 进程通信：实现相互合作的进程之间的信息交换
  4. 调度：作业需要经过调度才能执行，分为作业调度和进程调度
     - 作业调度：从后备队列选择若干作业，分配运行所需资源（首先分配内存）、建立进程，使之成为就绪进程，按一定规则插入就绪队列。
     - 进程调度：即分配CPU。从就绪队列中，按照一定的算法选出一个进行，为其分配CPU。

- 存储器管理

  - 内存分配：为每道程序分配内存空间，应具备以下结构和功能

    - 内存分配数据结构，记录内存空间使用情况
    - 内存分配功能
    - 内存回收功能

  - 内存保护：保证每道用户程序互不干扰

  - 地址映射：将**地址空间**的**逻辑地址**转换为**内存空间**的**物理地址**

    >一个应用程序经编译后，通常会形成若干个目标程序； 这些目标程序再经过链接便形成了可装入程序。这些程序的地址所形成的地址范围称为“地址空间” ，其中的地址称为“逻辑地址” 或“相对地址” 。此外，由内存中的一系列单元所限定的地址范围称为“内存空间” ，其中的地址称为“物理地址” 。

  - 内存扩充：借助虚拟存储技术，从逻辑上扩充内存。

    - 请求调入功能。允许在装入一部分用户程序和数据的情况下，便能启动该程序运行。运行过程中，所需程序数据未装入内存，可向OS发出请求，OS将所需部分调入内存。
    - 置换功能。若发现在内存中已无足够的空间来装入需要调入的程序和数据时，系统应能将内存中的一部分暂时不用的程序和数据调至盘上，以腾出内存空间，然后再将所需调入的部分装入内 存。

- 设备管理功能

  完成用户进程提出的I/O请求，分配设备、完成操作；提高CPU和I/O设备的利用率。

  为实现上述任务，设备管理应具有缓冲管理、设备分配和设备处理以及虚拟设备等功能。

  1. 缓冲管理：设置缓冲区，缓和CPU和I/O设备速度不匹配的矛盾，提高CPU利用率，提高系统吞吐量。
  2. 设备分配：根据用户进程的I/O请求、资源状况、设备分配策略等，分配所需设备。
  3. 设备处理：实现CPU和设备控制器之间的通信。

- 文件管理功能
  1. 文件存储空间管理：为每个文件分配外存空间。
  2. 目录管理：为每个文件建立目录项
  3. 文件的读写管理和保护

- 操作系统与用户之间的接口
  1. 用户接口
  2. 程序接口

## 二、进程管理

1、程序顺序执行时的特征

- 顺序性：每一操作必须在上一个操作完成后开始

- 封闭性：程序运行独占全部资源，不受外界影响

- 可再现性：只要程序执行环境和初始条件相同，当程序重复执行时，结果相同

2、程序并发执行的特征

- 间断性：并发执行的程序由于共享资源，以及为了完成同一任务相互合作，相互制约。将导致并发程序具有“执行-暂停-执行”间断性活动规律。

- 失去封闭性：多个程序共享资源。

- 不可再现性：由于失去封闭性，也就失去了再现性。即使执行环境和初始条件相同，结果却各不相同。

3． 进程的特征：

- 结构特征：进程实体由**程序段**、**相关的数据段**和**进程控制块（PCB）**三部分组成。

- 动态性：进程的实质是进程实体的一次执行过程。

- 并发性：多个进程实体同时存在于内存中，在能同一时间段内同时运行。

- 独立性：进程实体是可以独立运行/独立分配资源和独立接受调度的基本单位。而未建立 PCB 的程序不能作为一个单独的单位参与运行。

- 异步性：指进程按各自独立的，不可预知的速度向前推进。

4、进程的定义：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。

5、进程的三个基本状态：

- 就绪状态：进程已分配到除了 CPU 之外的所有必要资源，只要再获得 CPU，便可立即执行。

- 执行状态：进程已获得 CPU，程序正在运行。
- 阻塞状态：进程的暂停状态称为阻塞状态。致使进程阻塞的典型事件有：请 求I/O，申请缓冲空间等。

![image-20210511163625003](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210511163625003.png)

6、进程的挂起状态

1. 引入挂起状态的原因有：终端用户请求、父进程请求、负荷调节的需求、操作系统需求。<br>**挂起的原因，都是外部的，不是程序本身的原因**

2. 进程状态的转换

   在引入挂起状态后，又将增加挂起状态(静止状态)和非挂起状态(活动状态)之间的相互转换。

   - 活动就绪 → 静止就绪。没挂起前，活动就绪；挂起后，静止就绪。处于静止就绪的进程不再被调度执行。
   - 活动阻塞 → 静止阻塞。处于静止阻塞的进程在所期待的事件出现后，将从静止阻塞转为静止就绪。
   - 静止就绪 → 活动就绪。静止就绪**激活**后变为活动就绪，此时可以被调度执行。
   - 静止阻塞 → 活动阻塞。静止阻塞**激活**后变为活动阻塞

![image-20210511165756275](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210511165756275.png)

7、创建状态和结束状态（了解即可）

![image-20210511170128701](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210511170128701.png)

![image-20210511170210310](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210511170210310.png)

创建状态：首先创建一个 PCB，将该进程转入就绪状态并插入就绪队列。

进程状态：首先等待操作系统进行善后处理，然后清空 PCB，并将 PCB 空间返还系统。

5． 进程控制块 PCB

- 进程控制块的作用

  PCB 记录了操作系统所需的、用于描述进程当前情况以及控制进程运行的全部信息。使得一个在多道程序环境下不能独立运行的程序(含数据)，成为一个能独立运行的基本单位。**PCB是进程存在的惟一标志。**

- 进程控制块PCB中的信息

  1. 进程标识符：用于唯一的标识一个进程，一个进程通常由两种标识符：
     - 内部标识符：进程序号，为方便系统使用。
     - 外部标识符：创建者提供，由用户（进程）在访问该进程时使用。
  2. 处理机状态：由各种寄存器中的内容组成。
     - 通用寄存器：暂存信息
     - 指令计数器：下一条指令地址
     - 程序状态字PSW：状态信息，如条件码、执行方式
     - 用户栈指针：存放过程和调用参数、地址。
  3. 进程调度信息：进程状态、进程优先级、进程调度所需的其他信息、事件（阻塞原因）。
  4. 进程控制信息
     - 程序和数据的地址
     - 进程同步和通信机制
     - 资源清单，除CPU外所需资源及已分配的清单。
  5. PCB组织信息：下一个进程PCB的首地址。

- 进程控制块的组织方式

  1. 链式方式：把同一状态的 PCB，用链接字链接成一个队列，形成就绪队列、若干个阻塞队列和空白队列。

     ![image-20210511181815940](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210511181815940.png)

  2. 索引方式：根据进程状态建立几张索引表，如就绪索引表、阻塞索引表等，并把各个索引表在内存的首地址记录在内存的一些专用单元中。在每个索引表的表目中，记录有相应状态的某个 PCB 在PCB 表中的地址。

  ![image-20210511182114065](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210511182114065.png)

6、进程控制

进程控制一般是由OS的内核中的原语来实现的。

原语：由若干条指令组成的，用于完成一定功能的一个过程，是原子操作，指一个操作中的所有动作要么全做，要么全不做，即执行过程不可终端。原子操作在管态下执行，常驻内存。

- 进程图/树：用于描述一个进程的家族关系的有向树。

![image-20210511183610610](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210511183610610.png)

- 进程创建

  - 引起创建进程的事件有：用户登录、作业调度、提供服务、应用请求。

  >多道程序环境中，只有进程才能在系统运行。为使程序能运行，就必须为它创建进程。

  - 进程创建的过程

  1. 申请空白PCB
  2. 为新进程分配资源
  3. 初始化PCB。包括标识信息、处理机状态信息、处理机控制信息等。
  4. 将新进程插入就绪队列。

- 进程终止
  - 引起进程终止的事件：
    - 正常结束，进程完成。
    - 异常结束：越界错误、保护错、非法指令、运行超时
    - 外界干预：操作员干预、父进程请求（父进程有权终止子孙进程）、父进程终止（父终子终）
  - 进程终止的过程
    1. 根据被终止进程的标识符，从PCB集合中检索出该进程的 PCB，从中读出该进程的状态。
    2. 若被终止进程正处于执行状态，应立即终止该进程的执行， 并置调度标志为真，用于指示该进程被终止后应重新进行调度。
    3. 若该进程还有子进程，终止子进程。
    4. 将被终止进程所拥有的全部资源，或者归还给其父进程，或者归还给系统。
    5. 将被终止进程的PCB从队列/链表中移出。
- 进程阻塞与唤醒
  - 引发阻塞和唤醒的事件
    - 请求系统服务
    - 启动某种操作，需等待该操作完成后才能继续执行。例如启动了I/O操作。
    - 新数据尚未到达，合作进程需要等待另一个进程提供数据。
    - 无新工作可做。存在特定功能的系统进程，完成任务后，阻塞等待新任务。例如系统的发送进程。
  - 进程阻塞的过程：当正在执行的进程，发现以上阻塞时间无法继续执行，则调用block原语把自己阻塞。**进程的阻塞是进程自身的一种主动行为**。进入block过程后，由于此时该进程还处于执行状态， 所以应先立即停止执行，把进程控制块中的现行状态由“执行”改为 “阻塞” ，并将PCB插入阻塞队列。
  - 进程唤醒的过程：首先把被阻塞的进程从等待该事件的阻塞队列中移出，将其PCB中的现行状态由 阻塞改为就绪，然后再将该PCB插入到就绪队列中。

- 进程的挂起与激活
  - 进程挂起的过程：首先检查被挂起进程的状态，若处于活动就绪状态，便将其改为静止就绪； 对于活动阻塞状态的进程，则将之改为静止阻塞。
  - 进程激活的过程：先将进程从外存调入内存，检查该进程的现行状态，若是静止就绪，便将之改为活动就绪；若为静止阻塞，便将之改为活动阻塞。

7、进程同步

- 两种形式的制约关系

  由于资源共享和进程合作，进程间存在两种形式的制约关系：

  - 间接相互制约关系：资源共享。
  - 直接相互制约关系：进程合作。

- 临界资源

  对于临界资源，如打印机、磁带机等，进程间采取互斥方式，实现资源共享。

  **临界资源实现进程同步的例子：生产者-消费者问题**

- 临界区

  进程中访问临界资源的那段代码称为临界区。在临界区前面增加一段用于检查的代码，叫做为进入区。相应地，在临界区后面也要加上一段称为退出区，用于将临界区正被访问的标志恢复为未被访问的标志。余下区域为剩余区。

  - 同步机制应遵循的规则
    1. 空闲让进
    2. 忙则等待
    3. 有限等待，要求访问临界资源的进程，应保证在有限时间内能进入临界区，避免陷入“死等”状态。
    4. 让权等待，如进程不能进入临界区，立即释放处理结果，以免陷入“忙等”状态。

- 信号量机制

  1. 整型信号量

  整型信号量的定义：一个用于表示资源数目的整型量S，除初始化外，仅能通过两个标准的原子操作wait(S)和signal(S)来访问，即P、V操作。原子操作在执行时是不可中断的。

  ```c++
  void wait(int s){
      while(s<=0)//当没有资源可以利用时，等待
      	;
      s=s-1;//当有资源时，使用。每使用一个，资源个数减一
  }
  void signal(int s){
  	s=s+1;//释放资源，资源个数加一
  }
  ```

  2. 记录型信号量
  3. AND型信号量

  ​		有时候一个进程需要先获得两个或更多的共享资源后方能执行其任务，则这些共享资源都作为临界资源。AND同步机制的基本思想是：将进程在整个运行过程中需要的所有资源，一次性全部地分配给进程，待进程使用完后再一起释放。 只要尚有一个资源未能分配给进程，其它所有可能为之分配的资源也不分配给它。这样子就可以避免死锁。此时，需要在信号量中增加了一个“AND”条件，称同步wait操作，Swait。	

  ```C++
  Swait(S1，S2，…，Sn){
      while (TRUE){
          if (Si>=1 &&..&& Sn>=1){
              for(i =1; i<=n; i++) Si--;
              break;
          }
  		else{
         		 place the process in the waiting queue associated with the first Si found with Si<1,and set the program count of this process to the beginning of Swait operation
          }	
      }
  }
          
  Ssignal(S1，S2，…，Sn){
      while (TRUE){
          for(i=1; i<=n; i++){
              Si++;
              Remove all the process waiting in the queue associated with Si into the ready queue.
          }
      }
  }
  ```

- 信号量的应用

  1. 利用信号量实现进程互斥（竞争）

     ​		为使多个进程能互斥地访问某临界资源，只须为该资源设置一互斥 信号量mutex，并设其**初始值为1**，然后将各进程访问该资源的临界区置于wait(mutex)和signal(mutex)操作之间即可。

     ​		这样，每个欲访问该临界资源的进程在进入临界区之前，都要先对mutex执行wait操作，若该资源此刻未被访问，本次wait操作必然成功，进程便可进入自己的临界区，这时若再有其他进程也欲进入自己的临界区，此时由于对mutex执行wait操作定会失败，因而该进程阻塞，从而保证了该临界资源能被互斥地访问。 当访问临界资源的进程退出临界区后，又应对mutex执行signal操作，以便释放该临界资源。

  2. 利用信号量实现前趋关系 （协作）

     ​		利用信号量来描述程序或语句之间的前趋关系。设有两个并发执行的进程P1和P2。P1中有语句S1；P2中有语句S2。我们希望在S1执行后再执行S2。为实现这种前趋关系，我们只须使进程P1和P2共享一个公用信号量S，并赋予其初值为0，将signal(S)操作放在语句S1后面；而在S2 语句前面插入wait(S)操作。

     ​		由于S被初始化为0，这样，若P2先执行必定阻塞，只有在进程P1执 行完S1；signal(S)；操作后使S增为1时，P2进程方能执行语句S2成功。**例子：**

     图示出了一个前趋图，其中S1，S2，S3，…，S6是最简单的程序段(只有一条语句)。为使各程序段能正确执行，应设置若干个初始值 为“0”的信号量。如为保证S1→S2，S1→S3的前趋关系，应分别设置 信号量a 和b，同样，为了保证S2→S4，S2→S5，S3→S6，S4→S6和 S5→S6，应设置信号量c，d，e，f，g。

  ​        ![image-20210512092900375](C:%5CUsers%5CAsus%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210512092900375.png)

  ​			**代码框架描述：**

  ```c++
  p1(){S1;signal(a);signal(b);}
  p2(){wait(a);S2;signal(c);signal(d);}
  p3(){wait(b);S3;signal(e);}
  p4(){wait(c);S4;signal(f);}
  p5(){wait(d);S5;signal(g);}
  p6(){wait(f);wait(g);wait(e);S6;}
  main(){
      semaphore a,b,c,d,e,f,g;
      a.value = b.value = c.value = d.value = e.value = f.value = g.value = 0;
      cobegin
          p1();p2();p3();p4();p5();p6();
  	coend 
  }
  ```

#### 8、经典进程的同步问题

##### 生产者-消费者问题

假定在生产者和消费者之间的公用缓冲池中具有n 个缓冲区，这时可利用互斥信号量mutex 实现诸进程对缓冲池的互斥使用；利用信号量 empty 和 full 分别表示缓冲池中空缓冲区和满缓冲区的数量。又假定这些生产者和消费者相互等效，只要缓冲池未满，生产者便可将消息送入缓冲池；只要缓冲池未空，消费者便可从缓冲池中取走一个消息。

信号量有：互斥信号量 `mutex` ，(资源信号量)空缓存区数量`empty`，(资源信号量)使用缓存区数量`full`，分别初始化为1，n，0。

其他变量：in、out代表第一个资源和最后一个资源；buf[n] 代表缓冲区，类型为Item。

注意事项：

mutex 的作用：多个进程的互斥

empty 的作用：是否有缓冲区影响了生产者是否生产。

full 的作用：是否有产品影响了消费者是否能取

**应先执行对资源信号量的 wait 操作，然后再执行对互斥信号量的 wait 操作，否则可能引起进程死锁。**

![image-20210512210137576](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210512210137576.png)

```c++
int in = 0, out = 0;
item buffer[n];
semaphore metux = 1,empty = n,full = 0;
producer(){
    while( true ) {
        wait(empty);  // 等待空缓存区
        wait(metux);  // 等待互斥锁

        buffer[in] = nextp  // 将新资源放到buffer[in]位置 
        in = ( in + 1 ) % 10;
        empty -- ;
        signal(mutex);  // 释放互斥锁
        signal(full);  // 增加使用缓存区
    }
}

consumer() {
    while( true ) {
        wait(full);  // 等待使用缓存区
        wait(mutex); // 等待互斥锁

        // consumer
       	nextc = buffer[out]// 将buf[out]位置的的资源取走
        out = ( out + 1 ) % 10;
		ful--
        signal(mutex);  // 释放互斥锁
        signal(empty);  // 增加空缓存区
    }
}

void main(){
    cobegin
        producer();producer();
   	coend
}
```

##### 哲学家进餐问题

有五个哲学家共用一张圆桌，分别坐在周围的五张椅子上，在圆桌上有五个碗和五只筷子，他们的生活方式是交替地进行思考和进餐。平时，一个哲学家进行思考，饥饿时便试图取用其左右最靠近他的筷子，只有在他拿到两只筷子时才能进餐。进餐毕，放下筷子继续思考。

1、利用记录型信号量解决

五根筷子，五个信号量；所有信号量均初始化为1 ，第i为哲学家的活动：

```c++
semaphore chopstick[5] = [1,1,1,1,1];

while(true){
    wait(chopstick[i]);
    wait(chopstick[(i+1)%5]);
    
    eat;
    
    signal(chopstick[i]);
    signal(chopstick[(i+1)%5]);
    
    think;
}
```

可能引起死锁，如五位同时饥饿而拿起左边筷子，所有信号量为0，进入无限等待。

**解决死锁的解决方案**

1、至多只允许有四位哲学家同时去拿左边的筷子，最终能保证至 少有一位哲学家能够进餐，并在用毕时能释放出他用过的两只筷子， 从而使更多的哲学家能够进餐。

2、仅当哲学家的左、右两只筷子均可用时，才允许他拿起筷子进 餐。即and信号量。

**限制4位**

增加信号量N：允许同时进餐人数，初始值为4。

第i个哲学家的过程：

```c
while(true){
    wait(N);
    wait(chopstick[i]);
    wait(chopstick[(i+1)%5]);
    eat;
    signal(chopstick[i]);
    signal(chopstick[(i+1)%5]);
    signal(N);
    think;
}
```

**AND信号量**

第i个哲学家的过程：

```js
semaphore chopstick[5] = [1,1,1,1,1];
while(true){
    Swait(chopstick[i],chopstick[(i+1)%5]);//同时拿起左右筷子
    eat;
    Ssignal(chopstick[i],chopstick[(i+1)%5]);//同时放下
    think;
}
```

##### 读者-写者问题

保证一个 Writer 进程必须与其他进程互斥地访问共享对象的同步问题。

1、利用记录型信号量解决

信号量：写互斥信号量wmutex，读互斥信号量emutex(readcount是一个可被多个Reader进程访问的临界资源)

其他变量：读进程数：readcount、

```c
semaphore rmutex = 1,wmutex = 1; //读写之间互相制约
int readcount =0;
reader(){
    while(true){
        //开始读
        wait(rmutex)//等待读
        if(readcount == 0) wait(wmutex);//等待写
        readcount ++;//数量+
        signal(rmutex);//释放读
        
        ...read 读
        //读完之后
        wait(rmutex);//等待读
        readcount--;//数量-
        if(readcount == 0) signal(wmutex);//等待写
        signal(rmutex);//释放
    }
}

writer(){
    while(true){
        wait(wmutex);//等待写
        writer...//写
        signal(wmutex);//释放写
    }
}

void main(){
    cobegin
        reader();writer();
    coend
}
```

##### 理发师问题

角色有两个，理发师和顾客 只有一个理发师和一把理发椅子，另有N把椅子供顾客休息等待。没有顾客时，理发师休息，等待顾客 每个顾客来时，先看是否有椅子空位，有空位，坐下等待；否则不等待直接走。

信号量：理发师资源信号量barber，顾客资源信号量customers，互斥信号量mutex实现进程互斥，分别初始化为0,0,1（没有顾客时，理发师休息、刚开始顾客没来、进程互斥）

其他变量：顾客数量 count ，初始化为0

注意事项：理发师是一个循环，顾客多个，但每个只执行一次。

首先，空闲椅子的有无影响了等待顾客的数量，而顾客的有无影响了理发师是否开始理发，所以要使用不同的信号量来处理。customers这个信号量的作用，和生产者消费者里面的full的作用差不多。

```c++
semaphore barber = 0,customers = 0 ,mutex = 1;
int count = 0;

barber(){
	while(true){
		wait(customers);//barber等待顾客叫他
        wait(mutex);//等待互斥锁，只能被一个顾客叫醒
        count --;//等待区椅子空1
        cut_hair() //剪头发
        signal(barber);//剪发后 理发师资源被释放
        signal(mutex);//释放互斥锁
	}
}

customers(){
    wait(mutex);//等待互斥锁被释放
    if(count<n){ //人少，进入椅子等待
        count ++;
        signal(customers);//通知顾客资源信号量
		signal(mutex);//访问椅子结束
        wait(barber);//等待理发师
        get_haircut();//得到服务
    }else{
        signal(mutex);//走了，释放互斥锁
    }
}

void main(){
    cobegin
        barber();customers();customers();
    coend
}
```

## 三、处理机调度与死锁

1、高级调度

- 高级调度又称作业调度或长程调度，主要功能是依据某种算法，把外存上的处于后备队列的作业调入内存。

作业：在批处理系统中，是以作业为基本单位从外存调入内存的。

- 作业控制块 JCB：

是作业在系统中存在的标志，其中保存了系统对作业进行管理和调度所需的全部信息。每当作业进入系统，系统为每个作业创建一个 JCB。当作业完成，则系统回收分配给它的资源，撤销 JCB

- 作业调度：

根据 JCB 中的信息，审查系统能否满足用户作业的资源需求，按照一定算法，从外存后备队列中选择某些队列调入内存，并为它们创建进程，分配资源。然后再将新进程插入就绪队列。

- 每次作业调度需要考虑两个问题：

1. 决定接纳多少个作业
2. 决定接纳哪些作业，取决于调度算法。



2、低级调度（进程调度）：

进程调度用于决定就绪队列中的哪个进程应获得处理机。

- 进程调度的功能

保存处理机现场信息、按某种调度算法选取进程、把处理器分配给进程

- 进程调度的三个基本机制（和功能对应）

1． 排队器。进程按一定顺序排列成队列，挑选进程。

2． 分派器。分配CPU。

3． 上下文切换机制：保存当前进程状态、恢复选中要运行的新进程的状态。

- 进程调度方式

1. 非抢占式

   ​		一旦把处理机分配给某个进程后，会一直让它运行下去，直至此进程完成，或发生某些事件被阻塞时，才把处理机分配给其它进程。但难以满足紧急任务的需求。

2. 抢占式

   ​		允许调度程序根据某种原则暂停某个正在执行的进程，将已分配的处理机重新分配给另一个进程。可以防止一个长进程长时间占用处理机，能为大多数进程提供更公平的服务，但开销比非抢占式大。

   - 抢占式基于的原则：

     1． 优先权原则：通常一些重要和紧急的作业赋予较高的优先权。

     2． 短作业（进程）优先原则：当新到达的作业（进程）比正在执行的作业（进程）明显短时，将暂停当前长作业（进程）的执行，使短作业优先执行。

     3． 时间片原则：各个进程按时间片轮流运行。适用于分时系统。

     

3、 中级调度（中程调度，不再使用）：

中级调度是为了提高内存利用率和系统吞吐量，为此，应使那些暂时不能运行的进程让出内存资源，将它们调至外存上去等待。

这三种调度方式中，进程调度频率最高（短程调度），作业调度所需时间最长（长程调度），中级调度基于这两者之间。



4、 选择调度方式和调度算法的若干准则：

1. 面向用户（应用）的准则：

   - 周转时间短。评价批处理系统的性能、选择作业调度方式与算法
   - 响应时间快。常把响应时间长短用来评价分时系统的性能。
   - 截止时间的保证。评价实时系统性能、选择实时调度算法
   - 优先权准则。在批处理、分时和实时系统中都可以遵循优先权准则。

   周转时间：作业被提交给系统开始，到作业完成的这段时间间隔。包括四部分，作业在外存后备队列上等待调度时间，进程进入就绪队列上等待调度时间，进程执行时间，以及进程等待 I/O 操作完成的时间。

   **平均周转时间：**<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210513092013841.png" alt="image-20210513092013841" style="zoom:50%;" />

   **带权周转时间：**作业的周转时间T与系统为它提供服务的时间Ts之比，即W = T/Ts。

   **平均带权周转时间：**<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210513092328982.png" alt="image-20210513092328982" style="zoom:50%;" />

   响应时间：指从用户提交一个请求开始， 直至系统首次产生响应为止的时间间隔。它包括三部分时间：输入的请求信息传送到处理机的时间，处理机对请求信息进行处理的时间，以及将所形成的响应信息回送到终端显示器的时间。

   截止时间：某任务必须开始执行的最迟时间，或必须完成的最迟时间。

2. 面向系统的准则

   - 系统吞吐量高。评价批处理系统性能重要指标。

     标准：单位时间完成的任务多

   - 处理机利用率好。充分发挥硬件的效率。

   - 各类资源的平衡利用



5、调度算法

1. 先来先服务（FCFS）调度算法

   按先来后到的顺序，依次运行。FCFS算法有利于长作业（进程），而不利于短作业（进程）。有利于 cpu 繁忙型的作业，而不利于 I/O 繁忙型的作业，未能完全考虑作业的紧迫程度。

2. 短作业（进程）优先调度算法 SJ(P)F

   对短作业或短进程优先调度算法。该算法对长作业不利，未能完全考虑作业的紧迫程度。

   - SJF短作业优先：从后备队列中选择一个或若干个估计运行时间最短的作业，将其调入内存。

   - SPF短进程优先：从就绪队列中选择一个估计时间最短的进程，将处理机分配给它。

3. 非抢占式优先权调度算法（OS系统很少用）

   系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成。

4. 抢占式优先权调度算法

   系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另 一个其优先权更高的进程，就会有CPU重新分配。

5. 高响应比优先调度算法

   此算法是短作业优先算法的优化，使用动态优先权，并使作业的优先级随着等待时间的增加而以速率a提高，则长作业在等待一定的时间后，必然有机会分配到处理机。

   优先权的变化规律：<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210513105056644.png" alt="image-20210513105056644" style="zoom:50%;" />

   由于等待时间与服务时间之和就是系统对该作业的响应 时间，故该优先权又相当于响应比RP。

   <img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210513105246666.png" alt="image-20210513105246666" style="zoom:50%;" />

   该算法既照顾了短作业，又考虑了作业到达的 先后次序，不会使长作业长期得不到服务。但是需要计算响应比，增加了系统开销。

6. 基于时间片的轮转调度算法

   把CPU分配给队首进程，并令其执行一个时间片。当执行的时间片用完时，停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。适合分时系统。

7. 多级反馈队列调度算法

   设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。

- 优先权类型

  优先权优先调度算法，其关键在于：使用静态优先权，还是用动态优先权；如何确定进程的优先权。

  1. 静态优先权：是在创建进程时确定的，且在进程的整个运行期间保存不变。一般利用某个范围的一个整数表示。

     - 确定进程优先权的依据有
       - 进程类型，通常系统进程（接受进程、对换进程）优先权高于用户进程
       - 进程对资源的需求，估计进程执行时间和内存需求量，一般要求少的优先权高。
       - 用户要求。用户进程紧迫程度决定。

     简单易行，系统开销小，但不够精确，很 可能出现优先权低的作业(进程)长期没有被调度的情况。

  2. 动态优先权：在创建进程时所赋予的优先权，是可以随进程的推进或其等待时间的增加而改变的。

6、进程和线程

- 进程

  进程通常被定义为一个**正在运行的程序的实例**，它由两个部分组成：

  - PCB
  - 地址空间，包含所有可执行模块或DLL 模块的代码和数据。

  进程是不可调度的。若要使进程完成某项操作， 它必须拥有一个在它的环境中运行的线程，该线程负责执行包含在进程的地址空间中的代码。

7、产生死锁的原因和必要条件

死锁，是指多个进程在运行过程中因争夺资源而造成的一种僵局，使得进程无法向前推进。

- 产生死锁的原因：竞争资源、进程间推进顺序不当

  1． 竞争资源

  系统中的资源分为可剥夺性资源和非可剥夺性资源。前者指进程在获得这类资源后，该资源可以再被其他进程或系统剥夺。后者指当系统分配了这类资源后，不能够再行剥夺。

  竞争非剥夺资源：

  例如，系统中只有一个打印机和一个磁带机，供两个进程共享。若 A 进程已占用了打印机，B 进程已占用了磁带机。若此时，B 继续要求打印机，则由于产生 I/O 请求，B 将阻塞；若 A 有要求磁带机，则 A 也阻塞。因而两者都等待对方的资源，但它们又因为阻塞而不能继续推进，从而导致不能释放自己的资源。产生死锁。

  竞争临时性资源：

  指由一个进程产生，被另一个进程使用一短暂时间后便无用的资源，也称消耗性资源。

  **S1、S2和S3是临时性资源，进程之间的依赖关系。**如果每个进程的工作是先生产，再请求，就没问题；反之，如果生产依赖请求的资源，则会有问题。

  ![image-20210517225945262](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210517225945262.png)

  例如下述进程请求方式可能产生死锁

  P1 : REQUEST(S3); RELEASE(S1);

  P2 : REQUEST(S1); RELEASE(S2);

  P3 : REQUEST(S2); RELEASE(S3);

  2． 进程推进顺序不当：

  进程推进顺序不当会导致死锁。

- 产生死锁的必要条件：

  互斥条件：一段时间内某个资源只由一个进程占用。

  请求和保持条件：指进程已经保持了至少一个资源，但又提出新的资源请求，而该资源又被其他进程所占用。

  不剥夺条件：指进程已获得的资源，在未使用完成前，不能被剥夺。

  环路等待条件：指发生死锁时，必然存在一个进程-资源的环形链。

8、处理死锁的基本方法

预防死锁：破坏产生死锁的四个必要条件中的一个或几个条件。

避免死锁：在资源动态分配过程中，用某种方式阻止系统进入不安全状态。

检测死锁：不事先预防，也不检测系统是否进入不安全区，而是通过检测机制，及时检测出死锁的发生，然后采取适当措施消除死锁。

解除死锁：与检测死锁配套使用。常用方式是撤销或挂起一些进程，以便回收一些资源。

- 预防死锁

  1. 摒弃“请求和保持”条件

     在采用这种方法时，系统规定所有进程在开始运行之前， 都必须一次性地申请其在整个运行过程所需的全部资源。

  2. 摒弃“不剥夺”条件

     当一个已经保持了某些资源的进程，再提出新的 资源请求而不能立即得到满足时，必须释放它已经保持了的 所有资源，待以后需要时再重新申请。

  3. 摒弃“环路等待”条件

     系统将所有资源按类型进行线性排队， 并赋予不同的序号。所有进程对资源的请求必须严 格按照资源序号递增的次序提出，这样，在所形成的资源分 配图中，不可能再出现环路。

- 系统的安全状态

  在避免死锁的方法中，允许进程动态地申请资源，但系统在进行资源分配之前，应先计算此次资源分配的安全性。 若此次分配不会导致系统进入不安全状态，则将资源分配给 进程；否则，令进程等待。

  安全状态：指系统能按某种进程顺序(P1，P2，…， Pn)(称〈P1，P2，…，Pn〉序列为安全序列)，来为每个进程分配其所需的资源，直至满足每个进程对资源的最大需求。如果系统无法找到这样一个安全序列，则称系统进入不安全状态。

  不安全状态不一定会死锁，但当系统进入不安全 状态后，便有可能进而进入死锁状态；反之，只要系统处于 安全状态，系统便可避免进入死锁状态。因此，**避免死锁的实质在于：系统在进行资源分配时，如何使系统不进入不安全状态**

  **例子：**

9、利用银行家算法避免死锁

1. 银行家算法的数据结构

   （1）资源向量Available。这是一个含有m个元素的数组，代表每一类可用资源的数目，随该类资源的分配和回收而动态地改变。如果Available[j]=K，则表示系统中现有j类资源K个。

   （2）最大需求矩阵Max。这是一个n×m的矩阵，它定义了系统中n个进程对m类资源的最大需求。如果Max[i,j]=K，则表示进程i需要j类资源的最大数目为K。

   （3）分配矩阵Allocation。这也是一个n×m的矩阵，它定义了系统中每一类资源当前已分配给每一进程的资源数。 Allocation[i,j]=K，表示进程i当前已有j类资源的数目为K。

   （4）需求矩阵Need。这也是一个n×m的矩阵，用以表示每一个进程尚需的各类资源数。如果Need[i,j]=K，表示进程 i 还需要 j类资源K个，才能完成其任务。

   满足以下公式

   **`Need[i,j]= Max[i,j] - Allocation[i,j]`**

2. 银行家算法

   设Request i是进程Pi的请求向量，如果Request i[j]=K，表 示进程Pi需要K个j类资源。当Pi发出资源请求后，系统按下述步骤进行检查：

   (1) 如果Request i[j]≤Need[i,j]，便转向步骤(2)；否则认为出错，因为它所需要的资源数已超过它所宣布的最大值。

   (2) 如果Requesti[j]≤Available[j]，便转向步骤(3)；否则，表示尚无足够资源，Pi须等待。

   (3) 系统试探着把资源分配给进程P i，并修改下面数据结 构中的数值： `Available[j]:= Available[j]-Requesti[j];`

   `Allocation[i,j]:= Allocation[i,j]+Requesti[j];` 

   `Need[i,j]:= Need[i,j]-Requesti[j];`

   (4)系统执行安全性算法，检查此次资源分配后系统是否处于安全状态。若安全，才正式将资源分配给进程Pi，以完成本次分配；否则，将本次的试探分配作废，恢复原来的资源分配状态，让进程Pi等待。

10、安全性算法

​	系统所执行的安全性算法可描述如下：

​	 (1) 设置两个向量：

​	 ① 工作向量Work，它表示系统可提供给进程继续运行所需的各类资源数目，它含有m个元素，在执行安全算法开始时，Work:=Available。

​	 ② Finish，它表示系统是否有足够的资源分配给进程， 使之运行完成。开始时先做Finish[i]:=false；当有足够资源分配给进程时，再令Finish[i]:=true。

​	(2) 从进程集合中找到一个能满足下述条件的进程：

​	 ① Finish[i]=false； 

​	 ② Need[i,j]≤Work[j]； 若找到，执行步骤(3)，否则，执行步骤(4)。

​	(3) 当进程Pi获得资源后，可顺利执行，直至完成，并释放出分配给它的资源，故应执行：

​	`Work[j]:= Work[j]+Allocation[i,j]；`

​    ` Finish[i]:=true；`

 	go to step （2）；

​	(4) 如果所有进程的Finish[i]=true都满足，则表示系统处于安全状态；否则，系统处于不安全状态。

**银行家算法例子：**

假定系统中有五个进程{P0，P1，P2，P3，P4}和三类资源{A，B，C}，各种资源的数量分别为10、5、7，在T0时刻的资源分配情况如图所示

<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518091133205.png" alt="image-20210518091133205" style="zoom:80%;" />

(1) T0时刻的安全性：利用安全性算法对T0时刻的资源分配情况进行分析可知，在T0时刻存在着一个安全序列{P1，P3，P4，P2，P0}，故系统是安全的。

<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518093635692.png" alt="image-20210518093635692" style="zoom: 80%;" />

(2) P1请求资源：P1发出请求向量Request1(1，0，2)，系统按银行家算法进行检查：

`Request1(1，0，2)≤Need1(1，2，2)`

`Request1(1，0，2)≤Available1(3，3，2)`

③ 系统先假定可为P1分配资源，并修改Available， Allocation1和Need1向量，由此形成的资源变化情况如图中的圆括号所示

④ 再利用安全性算法检查此时系统是否安全。

![image-20210518094036747](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518094036747.png)

11、死锁的检测与解除

不想看，应该不是重点。

## 四、存储器管理

1、主存储器与寄存器

- 主存储器

  主存储器(简称内存或主存) ，用于保存进程运行时的程序和数据。**CPU的控制部件只能从主存储器中取得指令和数据，数据能够从主存储器读取并将它们装入到寄存器中，或者从寄存器存入到主存储器。**

- 寄存器

  寄存器访问速度最快，完全能与CPU协调工作。

2、程序的装入和链接

在多道程序环境下，要使程序运行，必须先为之创建进程。而创建进程的第一件事，便是将程序和数据装入内存。将一个用户源程序变为一个可在内存中执行的程序，需要经过一下步骤：

1、首先要编译，由编译程序将源程序编译成目标模块

2、其次是链接，由链接程序将编译后的目标模块，以及所需库函数链接起

来，形成一个完整的装入模块。

3、最后装入，由装入程序将装入模块装入内存。

<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518102522860.png" alt="image-20210518102522860" style="zoom:80%;" />

- 程序装入

1. 绝对装入方式：在编译时，如果知道程序将驻留在内存的什么位置，则，编译程序将产生绝对地址的目标代码。（适用于单道）
2. 可重定位装入方式：在多道程序环境下，所得到的目标模块的起始地址通常从 0 开始，程序中的其他地址也都是相对于起始地址计算的。此时可以采用可重定位方式装入，根据内存当前情况，装入到适当位置。采用可重定位装入程序将装入模块装入内存后，会使得装入模块的所有逻辑地址与实际装入内存的物理地址不同。
3. 动态运行时装入方式：可重定位装入方式不允许程序运行时在内存中移动位置，而动态方式可以。动态运行时的装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址装换为绝对地址，而是把这种地址转换推迟到程序真正要执行才开始。这就需要重定位寄存器的支持。

- 程序链接：

1. 静态链接：在程序运行前，先将各自目标模块及其所需库函数，链接成一个装入模块，以后不再拆开。属于事先链接。
2. 装入时动态链接：将目标模块，在装入内存时，采用边装入边链接的链接方式。
3. 运行时动态链接：对某些目标模块的链接，是在程序执行中需要该模块时，才对它进行链接。

- 静态链接

例如：有 A,B,C 三个目标模块，长度分别为 L,M,N。其中 A 中有 CALL B 语句，B 中有 CALL C语句。欲将 A,B,C 装配成一个装入模块。需要修改两个东西：

1） 对相对地址进行修改。

2） 变换外部调用符号，将调用符号换成相对地址。

<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518104111000.png" alt="image-20210518104111000" style="zoom:80%;" />

- 装入时动态链接：在装入一个目标模块时，若发生一个外部模块调用事件，将引起装入程序去找出相应的外部目标模块，并装入内存。

  优点：便于修改和更新，便于实现对目标模块的共享。

3、连续分配方式

1. 单一连续分配：适用于单用户、单任务的操作系统。内存分为系统区和用 区两部分，系统区仅提供给OS使用，用户区提供给用户使用。

2. 固定分区分配：将内存用户空间划分为若干个固定大小的区域，每个分区中只装入一道作业。允许有几道作业并发执行。

3. 动态分区分配：根据进程的实际需求，动态分配空间。在实现可变分区分配时，将涉及到分区分配中所用的数据结构、分区分配算法和分区的分配与回收操作这样三个问题。

   1）分区分配中的数据结构

   ​	   为了实现分区分配，系统中必须配置相应的数据结构，用来描述空闲分区和已分配分区的情况，为分配提供依据。常用的数据结构有以下两种形式：

   ​		①空闲分区表。在系统中设置一张空闲分区表，用于记录每个空闲分区的情况。每个空闲分区占一个表目，表目中包括分区序号、 分区始址及分区的大小等数据项。（不常用，因为不灵活）

   ​		②空闲分区链。为了实现对空闲分区的分配和链接，在每个分区的起始部分，设置一 些用于控制分区分配的信息，以及用于链接各分区所用的前向指针； 在分区尾部则设置一后向指针，通过前、后向链接指针，可将所有的 空闲分区链接成一个双向链，如图所示。为了检索方便，在分区尾部 重复设置状态位和分区大小表目。当分区被分配出去以后，把状态位 由“0”改为“1” ，同时将节点从链表删除。

   <img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518105535708.png" alt="image-20210518105535708" style="zoom:80%;" />

- 动态分区分配算法

  1） 首次适应 FF 算法：FF 算法要求空闲分区链以地址递增的次序链接。在分配内存时，从链首开始顺序查找，直至找到一个大小能满足要求的空闲分区为止，然后再按照作业的大小，从该分区中划出一块内存空间分配给请求者，剩余空闲分区仍留在空闲链中。

  2） 循环首次适应 NF 算法：在为进程分配内存空间时，不再是每次都从链首开始查找，而是从上一次找到的空闲分区的下一个空闲分区开始查找，直至找到满足要求的空闲分区，从中划分出一块满足要求大小的内存空间分配给作业。

  3） 最佳适应 BF 算法：每次为作业分配内存时，总是把能满足要求，又是最小的空闲分区分配给作业。要求将所有的空闲分区按其容量以从小到大的顺序形成一空闲分区 链。这样，第一次找到的能满足要求的空闲区，必然是最佳的。

  4） 最坏适应 WF 算法：要扫描整个空闲分区表或链表，总是挑选一个最大的空闲分区分割给作业，优点在于可使剩下的空闲分区不至于太小，产生碎片的几率很小。

  5） 快速适应 QF 算法：将空闲分区根据其容量大小进行分类，对于每一类具有相同容量的所有空闲分区，单独设立一个空闲分区链表。这样，系统中存在多个空闲分区链表，同时在内存中设立一张管理索引表，该表的每一个表项对应一种空闲分区类型，并记录该类型空闲分区链表头指针。

- 分区分配操作

  在动态分区存储管理方式中，主要操作是分配内存和回收内存

  1）分配内存

  ​	   系统应利用某种分配算法，从空闲分区链(表)中找到所需大小的 分区。设请求的分区大小为u.size，表中每个空闲分区的大小可表示 为m.size。若m.size-u.size≤size(size是事先规定的不再切割的剩 余分区的大小)，说明多余部分太小，可不再切割，将整个分区分配给 请求者；否则(即多余部分超过size)，从该分区中按请求的大小划分 出一块内存空间分配出去，余下的部分仍留在空闲分区链(表)中。然后，将分配区的首址返回给调用者。

  ![image-20210518113613995](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518113613995.png)

  2）回收内存

  当进程运行完毕释放内存时，系统根据回收区的首址，从空闲区 链(表)中找到相应的插入点，此时可能出现以下四种情况之一：

  (1) 回收区与插入点的前一个空闲分区F1相邻接。 

  (2) 回收分区与插入点的后一空闲分区F2相邻接。

  (3) 回收区同时与插入点的前、后两个分区邻接。 

  (4) 回收区与现有空闲区无邻接。是孤立分区，创建新节点，加 入空闲链表。

- 可重定位分区分配：

  在内存分配时，若在系统中有若干小的分区，总容量足够大，但单独一个却不能容下程序，这些分区也不相邻，无法把程序装入内存。引起了内存浪费，产生碎片。

  通过移动内存中的作业的位置，把原来多个分散的小分区拼凑成一个大分区的方法，称为紧凑法，提供内存利用率。但由于紧凑后的用户程序在内存中的位置发生改变，因此，需要重定位。

4、基本分页存储管理方式

- 页面：

分页存储管理是将一个进程的逻辑地址空间分成若干大小相等的片，称之为页。并给各个页加以编号，从 0 开始，如第0页、第1页等。

相应地，内存也分成与页面等大的若干个存储块，称为物理块或页框，同样为它们加以编号，如第0#块、1#块等。在为进程分配内存时，以块为单位将进程的若干页分别装入到多个可以不相邻的物理块中。由于进程的最后一页通常装不满而形成不可利用的碎片，称之为“页内碎片”。页面大小一般为 2 的幂。

- 页面地址结构：

分页地址由页号，偏移量（页内地址）组成。如下例：<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518130129913.png" alt="image-20210518130129913" style="zoom: 33%;" />

图中的地址长度为32位，其中0～11位为页内地址，即每页的大小为4 KB；12～31位为页号，地址空间最多允许有1M页（2^20页）。

若给定一个逻辑地址空间中的地址为A，页面的大小为L，则页号P和页内地址d可 按下式求得：<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518130405962.png" alt="image-20210518130405962" style="zoom:50%;" /><img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518130426216.png" alt="image-20210518130426216" style="zoom:50%;" />

其中，INT代表取整，MOD是取余函数。

例如，如果系统的页面大小为 1KB，设A = 2170 B，则由上式可以求得：

 P = 2，d = 122

- 页表

在分页系统中，允许将进程的各个页离散地存储在内存不同的 物理块中，但系统应能保证进程的正确运行，即能在内存中找到每 个页面所对应的物理块。系统要为每一个进程都建立一个页表。在进程地址空间内的所有页（0~n），依次在页表中有一页表项，记录了相应页在内存中的对应的物理块号。在配置了页表后，进程执行时，通过查找该表， 即可找到每页在内存中的物理块号。页表是实现从页号到物理块号的地址映射。

- 地址变换机构

​        该机构是实现从逻辑地址到物理地址的转换，页内地址和物理地址是一一对应的，地址变换机构的任务是将逻辑地址中的页号，转换为内存中的物理块号。借助页表实现。

1. 基本的地址变换机构：

   ​		页表大多驻留在内存中，进程未执行时，页表的始址和页表长度存放在本进程的PCB中。当调度程序调度到某进程时，才将这两个数据装入页表寄存器中。

   ​		当进程要访问某个逻辑地址中的数据时，以下步骤：

   ① 地址拆分（页号+页内地址） 

   ② 查找页表（出错检查：地址越界） 

   ③ 获得块号 

   ④ 重新拼合成物理地址

2. 具有快表的地址变换机构

   ​        为了提高地址变换速度，在地址变换机构中增设一个具有并行查询能力的特殊高速缓冲寄存器，称为“快表”，用以存放当前访问的那些页表项。此时的地址变换过程是：在 CPU 给出有效地址后，由地址变换机构自动将页号送入快表，并将此页号与快表中的所有页号做比较，若有匹配的，则表示要访问的页表项子在快表中。这样可以直接从快表中读取对应的物理块号。若不在，则还须再访问内存中的页表，找到后，将物理块号送至地址寄存器，同时将此表项加入快表的一个寄存器中，如果满了，则替换。

- 两级页表？？？

  以 32 位逻辑空间为例，当页面大小为 4KB（12 位），若采用一级页表结构，对应（32-12）20 位的页号，即页表项应有1兆个。若采用二级页表，则需要对页表分页，外层页表中的页内地址为 10 位，外层页号也为 10 位。

  ![image-20210518133425797](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518133425797.png)

  在页表中的每个表项中存放的是进程的某页在内存中的**物理块号**。而在外层页表的每个页表项中，所存放的是某页表分页的**首地址**。我们可以利用外层页表和页表这两级页表，来实现从进程的逻辑地址到内存中物理地址间的变换。

  ![image-20210518133827806](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518133827806.png)

- 三级页表？？？

5、虚拟存储器

虚拟存储器：具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统。

>​		基于局部性原理，应用程序在运行之前，没有必要全部装入内存， 仅须将那些当前要运行的少数页面或段先装入内存便可运行，其余部分暂留在盘上。 但如果程序在运行时，所要访问的页(段)尚未调入内存(称为缺页或缺 段)，此时程序应利用OS所提供的请求调页(段)功能，将它们调入内存， 以使进程能继续执行下去。如果此时内存已满，无法再装入新的页(段)， 则还须再利用页(段)的置换功能，将内存中暂时不用的页(段)调至盘上，腾出足够的内存空间后，再将要访问的页(段)调入内存，使程序继续执行下去。

- 虚拟存储器的实现方法

  1） 分页请求系统

  ​		在分页系统基础上，增加了请求调页功能和页面置换功能所形成的页式虚拟存储系统。

  2） 请求分段系统

  ​	在分段系统基础上，增加了请求调段及分段置换功能后所形成的段式虚拟存储系统。

- 虚拟存储器特征

  1. 多次性：一个作业被分成多次调入内存运行。
  2. 对换性:允许在作业的运行过程中进行换进、换出。
  3. 虚拟性:从逻辑上扩充内存容量。

6、请求分页存储管理方式:

- 请求分页中的硬件支持: 页表机制。

  ​		在请求分页系统中所需要的主要数据结构是页表。其基本作用仍然是 将用户地址空间中的逻辑地址变换为内存空间中的物理地址。由于只将应 用程序的一部分调入内存，还有一部分仍在盘上，故须在页表中再增加若 干项，供程序(数据)在换进、换出时参考。在请求分页系统中的每个页表 项如下所示：

  ![image-20210518150344308](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518150344308.png)

  - 状态位P：用于指示该页是否已调入内存，供程序访问时参考。
  - 访问字段A：用于记录本页在一段时间内被访问的次数。
  - 修改位M：表示该页在调入内存后是否被修改过。
  - 外存地址：用于指出该页在外存上的地址，通常是物理块号， 供调入该页时参考。

- 缺页中断机构:

  当所要访问的页面不在内存中时，便产生缺页中断，请求OS将所缺页调入内存。

  它与通常的中断有明显区别:

  1) 在指令执行期间产生和处理中断信号。一般，CPU 都是在一条指令执行完毕后，才检验是否有中断请求到达。

  2) 一条指令在执行期间，可能产生多次缺页中断。

  **例子：**在执行一条指令COPY A TO B时，可能要产生 6次缺页中断，其中指令本身跨了两个页面，A和B又分别各是一个数据块，也都跨了两个页面。

  <img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518150750289.png" alt="image-20210518150750289" style="zoom:80%;" />

7、内存分配策略和分配算法：

为进程分配内存时，需要考虑三个问题：

1） 最小物理块数的确定：是能保证进程正常运行所需要的最小物理块数。

2） 物理块的分配策略：

1. 固定分配局部置换：为每一个进程分配一定数目的物理块，在整个运行期间都不改变。如果进程再发生缺页，只能从给它分配的那些进程中置换出页来使用。
2. 可变分配全局置换：先为系统中的每个进程分配一定数目的物理块，而 OS 也保留一个空闲物理块队列。当缺页时，由系统从空闲物理块队列取出一个物理块分配给该进程，只有当系统中的空闲块都用完，OS才会采用调度策略换出一部分页。
3. 可变分配局部置换:为每个进程分配一定数目的物理块，但发生缺页时，只允许从该进程在内存中的页面选出一个页换出。

- 物理块分配算法

  1） 平均分配算法：

  ​		将系统中的所有可供分配的物理块平均分配给各个进程。当系统中有100个物理块，有5个进程在运行时，每个进程可分得20个物理块。

  2） 按比例分配算法：

  ​		根据进程的大小按比例分配物理块。如果系统中共有n个进程，每个进程的页面数为Si，则系统中各进程页面数的总和为：<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518151656505.png" alt="image-20210518151656505" style="zoom:50%;" />

  ​		又假定系统中可用的物理块总数为m，则每个进程所能分到的物理块 数为bi，将有：<img src="http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518151725236.png" alt="image-20210518151725236" style="zoom:50%;" />

  b应该取整，它必须大于最小物理块数。

  3） 考虑优先权的分配算法：

  ​		将内存中的可供分配的所有物理块分为两部分，一部分按比例分配给各个进程，另一部分则根据各进程的优先权，适时增加其相应份额后，分配给进程。

8、页面置换算法

1） 最佳置换算法：

​		所选择被淘汰的页面，是以后永远不使用的，或许是在最长(未来)时间内不再 被访问的页面。

​		**例子：**假定系统为某进程分配了三个物理块，并考虑有以下的页面号引用 串：`7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1`

​		进程运行时，先将7，0，1三个页面装入内存。以后，当进程要访问页面2时，将会产生缺页中断。此时OS根据最佳置换算法，将选择页面7予以淘汰。这是因为页面0将作为第5个被访问的页面，页面1是第14个被访问的页面，而页面7则要在第18次页面访问时才需调入。

​		下次访问页面 0时，因它已在内存而不必产生缺页中断。当进程访问页面3时，又将引起页面1被淘汰；因为，它在现有的1，2，0三个页面中，将是以后最晚才被访问的。采用最佳置换算法发生了**6次页面置换。**

![image-20210518153339121](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518153339121.png)

2） 先进先出FIFO页面置换算法：

​		总是淘汰最先进入内存的页面，即选择在内存中驻留时间最长的页面予以淘汰。

​		**例子：**假定系统为某进程分配了三个物理块，并考虑有以下的页面号引用 串：`7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1`

​		当进程第一次访问页面2时，将把第7页换出，因为它是最先被调入内存的；在第一次访问页面3时，又将把第0页换出，因为它在 现有的2，0，1 三个页面中是最老的页。由图可以看出，利用FIFO算法时进行了12次页面置换，比最佳置换算法正好多一倍。![image-20210518153531982](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518153531982.png)

​	3） 最近最久未使用 LRU 置换算法：

​			LRU置换算法是选择最近、最久未使用的页面予以淘汰。该算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间t，当须淘汰一个页面时， 选择现有页面中其t值最大的，即最近最久未使用的页面予以淘汰。

​		**例子：**假定系统为某进程分配了三个物理块，并考虑有以下的页面号引用 串：`7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1`![image-20210518154030469](http://ruoruochen-img-bed.oss-cn-beijing.aliyuncs.com/img/image-20210518154030469.png)